{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4f59b2f-6926-4e4e-a3cf-1c01bebe2d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import tarfile\n",
    "from tensorflow.keras import layers, models, losses\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "077585dc-8f17-46ed-94e4-feeb7a078a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file, test_or_data, batch_number):\n",
    "    with tarfile.open(file, 'r:gz') as tar:\n",
    "        tar.extractall()\n",
    "    \n",
    "    if test_or_data == 'data':\n",
    "        extracted_file = f'cifar-10-batches-py/{test_or_data}_batch_{batch_number}' \n",
    "    if test_or_data == 'test':\n",
    "        extracted_file = f'cifar-10-batches-py/{test_or_data}_batch'\n",
    "    \n",
    "    with open(extracted_file, 'rb') as fo:\n",
    "        data_dict = pickle.load(fo, encoding='bytes')\n",
    "    \n",
    "    return data_dict\n",
    "\n",
    "def convert_flat_to_matrix(image_flat):\n",
    "    image = np.zeros((32, 32, 3), dtype=np.uint8)\n",
    "    image[:, :, 0] = image_flat[0:1024].reshape(32, 32)  # Red channel\n",
    "    image[:, :, 1] = image_flat[1024:2048].reshape(32, 32)  # Green channel\n",
    "    image[:, :, 2] = image_flat[2048:3072].reshape(32, 32)  # Blue channel\n",
    "    return image\n",
    "\n",
    "def prepare_training_data():\n",
    "    train_data = []\n",
    "    train_labels = []\n",
    "    for i in range(1, 6):\n",
    "        data_batch = unpickle('cifar-10-python.tar.gz', 'data', i)\n",
    "        for image_flat, label in zip(data_batch[b'data'], data_batch[b'labels']):\n",
    "            image = convert_flat_to_matrix(image_flat)\n",
    "            train_data.append(image / 255.0)\n",
    "            train_labels.append(label)\n",
    "    return np.array(train_data), np.array(train_labels)\n",
    "\n",
    "def prepare_test_data():\n",
    "    test_data = []\n",
    "    test_labels = []\n",
    "    data_batch = unpickle('cifar-10-python.tar.gz', 'test', 0)\n",
    "    for image_flat, label in zip(data_batch[b'data'], data_batch[b'labels']):\n",
    "        image = convert_flat_to_matrix(image_flat)\n",
    "        test_data.append(image / 255.0)\n",
    "        test_labels.append(label)\n",
    "    return np.array(test_data), np.array(test_labels)\n",
    "\n",
    "def initialize_cnn(pooling_type, conv_width):\n",
    "    input_shape = (32, 32, 3)\n",
    "\n",
    "    # Create a Sequential model\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    # Add the input layer with the defined input shape\n",
    "    model.add(layers.Input(shape=input_shape))\n",
    "    \n",
    "    # Add convolutional layers\n",
    "    model.add(layers.Conv2D(32, (conv_width, conv_width), activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(pooling_type((2, 2)))\n",
    "    model.add(layers.Dropout(0.25))\n",
    "    model.add(layers.Conv2D(64, (conv_width, conv_width), activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Conv2D(128, (conv_width, conv_width), activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(pooling_type((2, 2)))\n",
    "    model.add(layers.Dropout(0.25))\n",
    "    model.add(layers.Conv2D(128, (conv_width, conv_width), activation='relu'))\n",
    "    \n",
    "    # Flatten and add dense layers\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dropout(0.25))\n",
    "    model.add(layers.Dense(10))\n",
    "    return model\n",
    "\n",
    "def map_function_to_str(function):\n",
    "    if function == layers.MaxPooling2D:\n",
    "        return 'max_pooling'\n",
    "    if function == layers.AveragePooling2D:\n",
    "        return 'average_pooling'\n",
    "    raise \"Unsupported function\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b62b6fd-a8d9-4fdf-bd42-2a22071a3261",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = prepare_training_data()\n",
    "x_test, y_test = prepare_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c67549d-3512-4a43-946c-dd706acc9cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c6a6c41-a6ac-471d-af81-215061bdc39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = initialize_cnn(layers.MaxPooling2D, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9ed168-6f66-4f06-b04d-4dc94019452a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m   1/1563\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m59:49\u001b[0m 2s/step - accuracy: 0.0312 - loss: 3.5474"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jkuta\\miniconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 26ms/step - accuracy: 0.3302 - loss: 1.8389 - val_accuracy: 0.4226 - val_loss: 1.7664\n",
      "Epoch 2/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 26ms/step - accuracy: 0.4966 - loss: 1.4058 - val_accuracy: 0.5444 - val_loss: 1.2828\n",
      "Epoch 3/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 27ms/step - accuracy: 0.5589 - loss: 1.2602 - val_accuracy: 0.6032 - val_loss: 1.1477\n",
      "Epoch 4/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 28ms/step - accuracy: 0.5936 - loss: 1.1550 - val_accuracy: 0.5873 - val_loss: 1.2885\n",
      "Epoch 5/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 28ms/step - accuracy: 0.6215 - loss: 1.0892 - val_accuracy: 0.6714 - val_loss: 0.9577\n",
      "Epoch 6/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 28ms/step - accuracy: 0.6449 - loss: 1.0286 - val_accuracy: 0.5860 - val_loss: 1.3043\n",
      "Epoch 7/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 27ms/step - accuracy: 0.6639 - loss: 0.9791 - val_accuracy: 0.6927 - val_loss: 0.9260\n",
      "Epoch 8/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 29ms/step - accuracy: 0.6754 - loss: 0.9406 - val_accuracy: 0.7110 - val_loss: 0.8469\n",
      "Epoch 9/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 29ms/step - accuracy: 0.6838 - loss: 0.9094 - val_accuracy: 0.7041 - val_loss: 0.8697\n",
      "Epoch 10/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 27ms/step - accuracy: 0.6984 - loss: 0.8766 - val_accuracy: 0.7047 - val_loss: 0.9164\n",
      "Epoch 11/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 27ms/step - accuracy: 0.7106 - loss: 0.8442 - val_accuracy: 0.6429 - val_loss: 1.2004\n",
      "Epoch 12/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 28ms/step - accuracy: 0.7165 - loss: 0.8288 - val_accuracy: 0.7397 - val_loss: 0.7787\n",
      "Epoch 13/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 29ms/step - accuracy: 0.7231 - loss: 0.8003 - val_accuracy: 0.7295 - val_loss: 0.7993\n",
      "Epoch 14/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 27ms/step - accuracy: 0.7316 - loss: 0.7950 - val_accuracy: 0.6439 - val_loss: 1.3097\n",
      "Epoch 15/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 29ms/step - accuracy: 0.7377 - loss: 0.7749 - val_accuracy: 0.6914 - val_loss: 1.0130\n",
      "Epoch 16/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 28ms/step - accuracy: 0.7464 - loss: 0.7563 - val_accuracy: 0.7544 - val_loss: 0.7328\n",
      "Epoch 17/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 28ms/step - accuracy: 0.7495 - loss: 0.7355 - val_accuracy: 0.7644 - val_loss: 0.6954\n",
      "Epoch 18/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 28ms/step - accuracy: 0.7514 - loss: 0.7294 - val_accuracy: 0.7571 - val_loss: 0.7483\n",
      "Epoch 19/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 27ms/step - accuracy: 0.7563 - loss: 0.7131 - val_accuracy: 0.7571 - val_loss: 0.7366\n",
      "Epoch 20/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 29ms/step - accuracy: 0.7580 - loss: 0.7053 - val_accuracy: 0.7609 - val_loss: 0.7227\n",
      "Epoch 21/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 28ms/step - accuracy: 0.7634 - loss: 0.6913 - val_accuracy: 0.7714 - val_loss: 0.7190\n",
      "Epoch 22/50\n",
      "\u001b[1m 159/1563\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m36s\u001b[0m 26ms/step - accuracy: 0.7768 - loss: 0.6634"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame(columns = ['epochs', 'train_loss', 'train_acc', 'test_loss', 'test_acc'])\n",
    "results_df.set_index('epochs', inplace=True)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "batch_size = 32\n",
    "train_data_gen = datagen.flow(x_train, y_train, batch_size=batch_size)\n",
    "steps_per_epoch = x_train.shape[0]//batch_size\n",
    "history = model.fit(train_data_gen, epochs=50, batch_size = 64, validation_data = (x_test, y_test))\n",
    "[*model.evaluate(x_train, y_train), *model.evaluate(x_test, y_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cab47f-08c0-4d30-b1b1-517824dc56ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "[*model.evaluate(x_train, y_train), *model.evaluate(x_test, y_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b331d474-f5a2-46a4-ad49-2a10f6be573d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example to make sure I understand how these images work\n",
    "data = unpickle('cifar-10-python.tar.gz', 'test', 1)\n",
    "image_flat = data[b'data'][0]\n",
    "image = convert_flat_to_matrix(image_flat)\n",
    "\n",
    "# Display the image\n",
    "plt.imshow(image)\n",
    "plt.title(f'Image {0}')\n",
    "plt.show()\n",
    "\n",
    "data[b'labels'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb33d2e1-7296-4511-9888-67c5f97046b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, model in model_dict.items():\n",
    "    predictions = model.predict(x_test)\n",
    "\n",
    "    # Example output shapes\n",
    "    print('Shape of predictions:', predictions.shape)  # Shape will depend on your model and task\n",
    "    \n",
    "    # Example of accessing predictions for the first sample\n",
    "    first_prediction = predictions[0]\n",
    "    print('First prediction:', first_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d8066e-9f76-4fac-b51f-e51dbdf67ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax(first_prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
