{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4f59b2f-6926-4e4e-a3cf-1c01bebe2d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import tarfile\n",
    "from tensorflow.keras import layers, models, losses\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "077585dc-8f17-46ed-94e4-feeb7a078a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file, test_or_data, batch_number):\n",
    "    with tarfile.open(file, 'r:gz') as tar:\n",
    "        tar.extractall()\n",
    "    \n",
    "    if test_or_data == 'data':\n",
    "        extracted_file = f'cifar-10-batches-py/{test_or_data}_batch_{batch_number}' \n",
    "    if test_or_data == 'test':\n",
    "        extracted_file = f'cifar-10-batches-py/{test_or_data}_batch'\n",
    "    \n",
    "    with open(extracted_file, 'rb') as fo:\n",
    "        data_dict = pickle.load(fo, encoding='bytes')\n",
    "    \n",
    "    return data_dict\n",
    "\n",
    "def convert_flat_to_matrix(image_flat):\n",
    "    image = np.zeros((32, 32, 3), dtype=np.uint8)\n",
    "    image[:, :, 0] = image_flat[0:1024].reshape(32, 32)  # Red channel\n",
    "    image[:, :, 1] = image_flat[1024:2048].reshape(32, 32)  # Green channel\n",
    "    image[:, :, 2] = image_flat[2048:3072].reshape(32, 32)  # Blue channel\n",
    "    return image\n",
    "\n",
    "def prepare_training_data():\n",
    "    train_data = []\n",
    "    train_labels = []\n",
    "    for i in range(1, 6):\n",
    "        data_batch = unpickle('cifar-10-python.tar.gz', 'data', i)\n",
    "        for image_flat, label in zip(data_batch[b'data'], data_batch[b'labels']):\n",
    "            image = convert_flat_to_matrix(image_flat)\n",
    "            train_data.append(image / 255.0)\n",
    "            train_labels.append(label)\n",
    "    return np.array(train_data), np.array(train_labels)\n",
    "\n",
    "def prepare_test_data():\n",
    "    test_data = []\n",
    "    test_labels = []\n",
    "    data_batch = unpickle('cifar-10-python.tar.gz', 'test', 0)\n",
    "    for image_flat, label in zip(data_batch[b'data'], data_batch[b'labels']):\n",
    "        image = convert_flat_to_matrix(image_flat)\n",
    "        test_data.append(image / 255.0)\n",
    "        test_labels.append(label)\n",
    "    return np.array(test_data), np.array(test_labels)\n",
    "\n",
    "def initialize_cnn(pooling_type, conv_width):\n",
    "    input_shape = (32, 32, 3)\n",
    "\n",
    "    # Create a Sequential model\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    # Add the input layer with the defined input shape\n",
    "    model.add(layers.Input(shape=input_shape))\n",
    "    \n",
    "    # Add convolutional layers\n",
    "    model.add(layers.Conv2D(32, (conv_width, conv_width), activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(pooling_type((2, 2)))\n",
    "    model.add(layers.Dropout(0.25))\n",
    "    model.add(layers.Conv2D(64, (conv_width, conv_width), activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(pooling_type((2, 2)))\n",
    "    model.add(layers.Dropout(0.25))\n",
    "    model.add(layers.Conv2D(128, (conv_width, conv_width), activation='relu'))\n",
    "    \n",
    "    # Flatten and add dense layers\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dropout(0.25))\n",
    "    model.add(layers.Dense(10))\n",
    "    return model\n",
    "\n",
    "def map_function_to_str(function):\n",
    "    if function == layers.MaxPooling2D:\n",
    "        return 'max_pooling'\n",
    "    if function == layers.AveragePooling2D:\n",
    "        return 'average_pooling'\n",
    "    raise \"Unsupported function\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b62b6fd-a8d9-4fdf-bd42-2a22071a3261",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = prepare_training_data()\n",
    "x_test, y_test = prepare_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c67549d-3512-4a43-946c-dd706acc9cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    zoom_range=0.2\n",
    ")\n",
    "\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c6a6c41-a6ac-471d-af81-215061bdc39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = initialize_cnn(layers.MaxPooling2D, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de9ed168-6f66-4f06-b04d-4dc94019452a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jkuta\\miniconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 24ms/step - accuracy: 0.7110 - loss: 0.8509 - val_accuracy: 0.8000 - val_loss: 0.5961\n",
      "Epoch 2/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 23ms/step - accuracy: 0.7106 - loss: 0.8393 - val_accuracy: 0.7941 - val_loss: 0.6179\n",
      "Epoch 3/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 24ms/step - accuracy: 0.7159 - loss: 0.8354 - val_accuracy: 0.7873 - val_loss: 0.6398\n",
      "Epoch 4/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 25ms/step - accuracy: 0.7153 - loss: 0.8328 - val_accuracy: 0.7707 - val_loss: 0.7057\n",
      "Epoch 5/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 25ms/step - accuracy: 0.7148 - loss: 0.8379 - val_accuracy: 0.7935 - val_loss: 0.6196\n",
      "Epoch 6/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 24ms/step - accuracy: 0.7169 - loss: 0.8359 - val_accuracy: 0.7224 - val_loss: 0.8692\n",
      "Epoch 7/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 24ms/step - accuracy: 0.7094 - loss: 0.8409 - val_accuracy: 0.7496 - val_loss: 0.8103\n",
      "Epoch 8/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 24ms/step - accuracy: 0.7146 - loss: 0.8287 - val_accuracy: 0.7536 - val_loss: 0.7497\n",
      "Epoch 9/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 24ms/step - accuracy: 0.7121 - loss: 0.8331 - val_accuracy: 0.7875 - val_loss: 0.6436\n",
      "Epoch 10/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 22ms/step - accuracy: 0.7114 - loss: 0.8433 - val_accuracy: 0.8027 - val_loss: 0.5940\n",
      "Epoch 11/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 22ms/step - accuracy: 0.7125 - loss: 0.8333 - val_accuracy: 0.7812 - val_loss: 0.6780\n",
      "Epoch 12/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 21ms/step - accuracy: 0.7166 - loss: 0.8274 - val_accuracy: 0.7436 - val_loss: 0.7885\n",
      "Epoch 13/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 21ms/step - accuracy: 0.7120 - loss: 0.8281 - val_accuracy: 0.7510 - val_loss: 0.7736\n",
      "Epoch 14/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 21ms/step - accuracy: 0.7123 - loss: 0.8380 - val_accuracy: 0.7728 - val_loss: 0.6871\n",
      "Epoch 15/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 22ms/step - accuracy: 0.7159 - loss: 0.8300 - val_accuracy: 0.7298 - val_loss: 0.8946\n",
      "Epoch 16/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 21ms/step - accuracy: 0.7109 - loss: 0.8377 - val_accuracy: 0.8020 - val_loss: 0.5913\n",
      "Epoch 17/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 21ms/step - accuracy: 0.7125 - loss: 0.8344 - val_accuracy: 0.7028 - val_loss: 0.9363\n",
      "Epoch 18/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 21ms/step - accuracy: 0.7138 - loss: 0.8323 - val_accuracy: 0.7903 - val_loss: 0.6309\n",
      "Epoch 19/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 21ms/step - accuracy: 0.7178 - loss: 0.8274 - val_accuracy: 0.7521 - val_loss: 0.7840\n",
      "Epoch 20/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 21ms/step - accuracy: 0.7158 - loss: 0.8277 - val_accuracy: 0.7747 - val_loss: 0.6941\n",
      "Epoch 21/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 21ms/step - accuracy: 0.7128 - loss: 0.8339 - val_accuracy: 0.7576 - val_loss: 0.7357\n",
      "Epoch 22/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 21ms/step - accuracy: 0.7120 - loss: 0.8401 - val_accuracy: 0.7430 - val_loss: 0.8073\n",
      "Epoch 23/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 21ms/step - accuracy: 0.7153 - loss: 0.8340 - val_accuracy: 0.7904 - val_loss: 0.6386\n",
      "Epoch 24/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 21ms/step - accuracy: 0.7116 - loss: 0.8357 - val_accuracy: 0.7826 - val_loss: 0.6412\n",
      "Epoch 25/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 21ms/step - accuracy: 0.7145 - loss: 0.8239 - val_accuracy: 0.7684 - val_loss: 0.6994\n",
      "Epoch 26/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 21ms/step - accuracy: 0.7155 - loss: 0.8257 - val_accuracy: 0.7901 - val_loss: 0.6220\n",
      "Epoch 27/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 22ms/step - accuracy: 0.7203 - loss: 0.8233 - val_accuracy: 0.7878 - val_loss: 0.6340\n",
      "Epoch 28/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 21ms/step - accuracy: 0.7213 - loss: 0.8221 - val_accuracy: 0.7756 - val_loss: 0.7026\n",
      "Epoch 29/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 21ms/step - accuracy: 0.7152 - loss: 0.8381 - val_accuracy: 0.7404 - val_loss: 0.8659\n",
      "Epoch 30/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 22ms/step - accuracy: 0.7184 - loss: 0.8213 - val_accuracy: 0.7974 - val_loss: 0.5952\n",
      "Epoch 31/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 22ms/step - accuracy: 0.7166 - loss: 0.8252 - val_accuracy: 0.7481 - val_loss: 0.7867\n",
      "Epoch 32/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 21ms/step - accuracy: 0.7178 - loss: 0.8272 - val_accuracy: 0.8062 - val_loss: 0.5785\n",
      "Epoch 33/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 21ms/step - accuracy: 0.7180 - loss: 0.8250 - val_accuracy: 0.7805 - val_loss: 0.6809\n",
      "Epoch 34/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 22ms/step - accuracy: 0.7197 - loss: 0.8246 - val_accuracy: 0.7775 - val_loss: 0.6841\n",
      "Epoch 35/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 21ms/step - accuracy: 0.7229 - loss: 0.8136 - val_accuracy: 0.7770 - val_loss: 0.6803\n",
      "Epoch 36/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 21ms/step - accuracy: 0.7194 - loss: 0.8235 - val_accuracy: 0.7371 - val_loss: 0.8800\n",
      "Epoch 37/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 22ms/step - accuracy: 0.7163 - loss: 0.8259 - val_accuracy: 0.7788 - val_loss: 0.6985\n",
      "Epoch 38/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 21ms/step - accuracy: 0.7210 - loss: 0.8124 - val_accuracy: 0.8038 - val_loss: 0.5690\n",
      "Epoch 39/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 22ms/step - accuracy: 0.7222 - loss: 0.8071 - val_accuracy: 0.7843 - val_loss: 0.6403\n",
      "Epoch 40/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 21ms/step - accuracy: 0.7191 - loss: 0.8031 - val_accuracy: 0.7991 - val_loss: 0.5925\n",
      "Epoch 41/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 22ms/step - accuracy: 0.7198 - loss: 0.8161 - val_accuracy: 0.7692 - val_loss: 0.7158\n",
      "Epoch 42/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 21ms/step - accuracy: 0.7218 - loss: 0.8185 - val_accuracy: 0.7812 - val_loss: 0.6666\n",
      "Epoch 43/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 21ms/step - accuracy: 0.7203 - loss: 0.8148 - val_accuracy: 0.7844 - val_loss: 0.6562\n",
      "Epoch 44/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 21ms/step - accuracy: 0.7240 - loss: 0.8070 - val_accuracy: 0.7974 - val_loss: 0.6164\n",
      "Epoch 45/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 21ms/step - accuracy: 0.7171 - loss: 0.8225 - val_accuracy: 0.7626 - val_loss: 0.7460\n",
      "Epoch 46/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 21ms/step - accuracy: 0.7176 - loss: 0.8281 - val_accuracy: 0.7988 - val_loss: 0.5910\n",
      "Epoch 47/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 21ms/step - accuracy: 0.7204 - loss: 0.8148 - val_accuracy: 0.7580 - val_loss: 0.7809\n",
      "Epoch 48/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 21ms/step - accuracy: 0.7227 - loss: 0.8094 - val_accuracy: 0.7739 - val_loss: 0.7151\n",
      "Epoch 49/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 21ms/step - accuracy: 0.7246 - loss: 0.8162 - val_accuracy: 0.7892 - val_loss: 0.6386\n",
      "Epoch 50/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 21ms/step - accuracy: 0.7198 - loss: 0.8144 - val_accuracy: 0.7656 - val_loss: 0.7327\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame(columns = ['epochs', 'train_loss', 'train_acc', 'test_loss', 'test_acc'])\n",
    "results_df.set_index('epochs', inplace=True)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "batch_size = 32\n",
    "train_data_gen = datagen.flow(x_train, y_train, batch_size=batch_size)\n",
    "steps_per_epoch = x_train.shape[0]//batch_size\n",
    "history = model.fit(train_data_gen, epochs=50, batch_size = 64, validation_data = (x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b331d474-f5a2-46a4-ad49-2a10f6be573d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example to make sure I understand how these images work\n",
    "data = unpickle('cifar-10-python.tar.gz', 'test', 1)\n",
    "image_flat = data[b'data'][0]\n",
    "image = convert_flat_to_matrix(image_flat)\n",
    "\n",
    "# Display the image\n",
    "plt.imshow(image)\n",
    "plt.title(f'Image {0}')\n",
    "plt.show()\n",
    "\n",
    "data[b'labels'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb33d2e1-7296-4511-9888-67c5f97046b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, model in model_dict.items():\n",
    "    predictions = model.predict(x_test)\n",
    "\n",
    "    # Example output shapes\n",
    "    print('Shape of predictions:', predictions.shape)  # Shape will depend on your model and task\n",
    "    \n",
    "    # Example of accessing predictions for the first sample\n",
    "    first_prediction = predictions[0]\n",
    "    print('First prediction:', first_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d8066e-9f76-4fac-b51f-e51dbdf67ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax(first_prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
