{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4f59b2f-6926-4e4e-a3cf-1c01bebe2d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import tarfile\n",
    "from tensorflow.keras import layers, models, losses\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "077585dc-8f17-46ed-94e4-feeb7a078a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file, test_or_data, batch_number):\n",
    "    with tarfile.open(file, 'r:gz') as tar:\n",
    "        tar.extractall()\n",
    "    \n",
    "    if test_or_data == 'data':\n",
    "        extracted_file = f'cifar-10-batches-py/{test_or_data}_batch_{batch_number}' \n",
    "    if test_or_data == 'test':\n",
    "        extracted_file = f'cifar-10-batches-py/{test_or_data}_batch'\n",
    "    \n",
    "    with open(extracted_file, 'rb') as fo:\n",
    "        data_dict = pickle.load(fo, encoding='bytes')\n",
    "    \n",
    "    return data_dict\n",
    "\n",
    "def convert_flat_to_matrix(image_flat):\n",
    "    image = np.zeros((32, 32, 3), dtype=np.uint8)\n",
    "    image[:, :, 0] = image_flat[0:1024].reshape(32, 32)  # Red channel\n",
    "    image[:, :, 1] = image_flat[1024:2048].reshape(32, 32)  # Green channel\n",
    "    image[:, :, 2] = image_flat[2048:3072].reshape(32, 32)  # Blue channel\n",
    "    return image\n",
    "\n",
    "def prepare_training_data():\n",
    "    train_data = []\n",
    "    train_labels = []\n",
    "    for i in range(1, 6):\n",
    "        data_batch = unpickle('cifar-10-python.tar.gz', 'data', i)\n",
    "        for image_flat, label in zip(data_batch[b'data'], data_batch[b'labels']):\n",
    "            image = convert_flat_to_matrix(image_flat)\n",
    "            train_data.append(image / 255.0)\n",
    "            train_labels.append(label)\n",
    "    return np.array(train_data), np.array(train_labels)\n",
    "\n",
    "def prepare_test_data():\n",
    "    test_data = []\n",
    "    test_labels = []\n",
    "    data_batch = unpickle('cifar-10-python.tar.gz', 'test', 0)\n",
    "    for image_flat, label in zip(data_batch[b'data'], data_batch[b'labels']):\n",
    "        image = convert_flat_to_matrix(image_flat)\n",
    "        test_data.append(image / 255.0)\n",
    "        test_labels.append(label)\n",
    "    return np.array(test_data), np.array(test_labels)\n",
    "\n",
    "def initialize_cnn(pooling_type, conv_width):\n",
    "    input_shape = (32, 32, 3)\n",
    "\n",
    "    # Create a Sequential model\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    # Add the input layer with the defined input shape\n",
    "    model.add(layers.Input(shape=input_shape))\n",
    "    \n",
    "    # Add convolutional layers\n",
    "    model.add(layers.Conv2D(32, (conv_width, conv_width), activation='relu'))\n",
    "    model.add(pooling_type((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (conv_width, conv_width), activation='relu'))\n",
    "    model.add(pooling_type((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (conv_width, conv_width), activation='relu'))\n",
    "    \n",
    "    # Flatten and add dense layers\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(10))\n",
    "    return model\n",
    "\n",
    "def map_function_to_str(function):\n",
    "    if function == layers.MaxPooling2D:\n",
    "        return 'max_pooling'\n",
    "    if function == layers.AveragePooling2D:\n",
    "        return 'average_pooling'\n",
    "    raise \"Unsupported function\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b62b6fd-a8d9-4fdf-bd42-2a22071a3261",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = prepare_training_data()\n",
    "x_test, y_test = prepare_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c6a6c41-a6ac-471d-af81-215061bdc39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = dict()\n",
    "for pooling_type in [layers.MaxPooling2D, layers.AveragePooling2D]:\n",
    "    for conv_width in [2, 3, 4, 5]:   \n",
    "        model_dict[(pooling_type, conv_width)] = initialize_cnn(pooling_type, conv_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de9ed168-6f66-4f06-b04d-4dc94019452a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<class 'keras.src.layers.pooling.max_pooling2d.MaxPooling2D'>, 2)\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.3643 - loss: 1.7196 - val_accuracy: 0.5599 - val_loss: 1.2553\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.5732 - loss: 1.1963 - val_accuracy: 0.6357 - val_loss: 1.0294\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.6507 - loss: 0.9988 - val_accuracy: 0.6699 - val_loss: 0.9427\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.6925 - loss: 0.8882 - val_accuracy: 0.6875 - val_loss: 0.8903\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.7177 - loss: 0.8071 - val_accuracy: 0.6979 - val_loss: 0.8755\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.7420 - loss: 0.7396 - val_accuracy: 0.6893 - val_loss: 0.8843\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.7591 - loss: 0.6930 - val_accuracy: 0.7040 - val_loss: 0.8670\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.7739 - loss: 0.6542 - val_accuracy: 0.7103 - val_loss: 0.8629\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.7900 - loss: 0.6071 - val_accuracy: 0.7193 - val_loss: 0.8489\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.8011 - loss: 0.5733 - val_accuracy: 0.7151 - val_loss: 0.8461\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8146 - loss: 0.5300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7164 - loss: 0.8441\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.8111 - loss: 0.5406 - val_accuracy: 0.7174 - val_loss: 0.8657\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.8210 - loss: 0.5107 - val_accuracy: 0.7169 - val_loss: 0.8793\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.8323 - loss: 0.4755 - val_accuracy: 0.7126 - val_loss: 0.9119\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8441 - loss: 0.4470 - val_accuracy: 0.7173 - val_loss: 0.9426\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.8525 - loss: 0.4185 - val_accuracy: 0.7259 - val_loss: 0.9439\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8607 - loss: 0.3955 - val_accuracy: 0.7146 - val_loss: 0.9598\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.8708 - loss: 0.3698 - val_accuracy: 0.7179 - val_loss: 0.9983\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.8762 - loss: 0.3461 - val_accuracy: 0.7142 - val_loss: 1.0365\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8842 - loss: 0.3277 - val_accuracy: 0.7041 - val_loss: 1.1248\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8950 - loss: 0.3019 - val_accuracy: 0.7076 - val_loss: 1.1476\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9034 - loss: 0.2766\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7118 - loss: 1.1460\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8973 - loss: 0.2885 - val_accuracy: 0.7089 - val_loss: 1.1863\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9008 - loss: 0.2807 - val_accuracy: 0.7084 - val_loss: 1.1903\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.9096 - loss: 0.2571 - val_accuracy: 0.7098 - val_loss: 1.2532\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9150 - loss: 0.2398 - val_accuracy: 0.7061 - val_loss: 1.3035\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9174 - loss: 0.2319 - val_accuracy: 0.7013 - val_loss: 1.3422\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.9261 - loss: 0.2101 - val_accuracy: 0.7016 - val_loss: 1.3855\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9298 - loss: 0.1982 - val_accuracy: 0.7065 - val_loss: 1.4338\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9313 - loss: 0.1944 - val_accuracy: 0.6995 - val_loss: 1.5626\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9337 - loss: 0.1831 - val_accuracy: 0.7009 - val_loss: 1.5864\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9338 - loss: 0.1846 - val_accuracy: 0.7002 - val_loss: 1.5892\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9450 - loss: 0.1542\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7071 - loss: 1.5898\n",
      "(<class 'keras.src.layers.pooling.max_pooling2d.MaxPooling2D'>, 3)\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.3265 - loss: 1.7818 - val_accuracy: 0.5087 - val_loss: 1.3622\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.5513 - loss: 1.2586 - val_accuracy: 0.5960 - val_loss: 1.1418\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.6232 - loss: 1.0667 - val_accuracy: 0.6290 - val_loss: 1.0601\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.6674 - loss: 0.9469 - val_accuracy: 0.6626 - val_loss: 0.9593\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.6927 - loss: 0.8703 - val_accuracy: 0.6759 - val_loss: 0.9153\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.7193 - loss: 0.8003 - val_accuracy: 0.6939 - val_loss: 0.8787\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.7408 - loss: 0.7443 - val_accuracy: 0.7074 - val_loss: 0.8384\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.7552 - loss: 0.6960 - val_accuracy: 0.6997 - val_loss: 0.8688\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.7711 - loss: 0.6562 - val_accuracy: 0.7063 - val_loss: 0.8827\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.7831 - loss: 0.6184 - val_accuracy: 0.7094 - val_loss: 0.8539\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8042 - loss: 0.5582\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7104 - loss: 0.8446\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.7959 - loss: 0.5841 - val_accuracy: 0.7140 - val_loss: 0.8706\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8089 - loss: 0.5473 - val_accuracy: 0.7147 - val_loss: 0.8786\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.8135 - loss: 0.5280 - val_accuracy: 0.7058 - val_loss: 0.8951\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8270 - loss: 0.4988 - val_accuracy: 0.7104 - val_loss: 0.9167\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8374 - loss: 0.4655 - val_accuracy: 0.7020 - val_loss: 0.9474\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8392 - loss: 0.4539 - val_accuracy: 0.7103 - val_loss: 0.9348\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8515 - loss: 0.4205 - val_accuracy: 0.7112 - val_loss: 0.9572\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8579 - loss: 0.3987 - val_accuracy: 0.7177 - val_loss: 0.9840\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.8599 - loss: 0.3912 - val_accuracy: 0.7169 - val_loss: 1.0306\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8728 - loss: 0.3572 - val_accuracy: 0.7038 - val_loss: 1.1100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8688 - loss: 0.3595\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7059 - loss: 1.0961\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8791 - loss: 0.3411 - val_accuracy: 0.7040 - val_loss: 1.1339\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.8869 - loss: 0.3193 - val_accuracy: 0.7015 - val_loss: 1.1583\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8901 - loss: 0.3085 - val_accuracy: 0.7058 - val_loss: 1.1454\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8954 - loss: 0.2895 - val_accuracy: 0.7056 - val_loss: 1.1495\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.9008 - loss: 0.2744 - val_accuracy: 0.7042 - val_loss: 1.2267\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9048 - loss: 0.2648 - val_accuracy: 0.7034 - val_loss: 1.2436\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9107 - loss: 0.2511 - val_accuracy: 0.6983 - val_loss: 1.3393\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9167 - loss: 0.2342 - val_accuracy: 0.6970 - val_loss: 1.3821\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.9185 - loss: 0.2268 - val_accuracy: 0.6935 - val_loss: 1.4238\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9238 - loss: 0.2169 - val_accuracy: 0.6911 - val_loss: 1.4938\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9261 - loss: 0.2041\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6885 - loss: 1.4735\n",
      "(<class 'keras.src.layers.pooling.max_pooling2d.MaxPooling2D'>, 4)\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.3429 - loss: 1.7750 - val_accuracy: 0.5197 - val_loss: 1.3281\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.5582 - loss: 1.2385 - val_accuracy: 0.6098 - val_loss: 1.1217\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.6217 - loss: 1.0743 - val_accuracy: 0.6452 - val_loss: 1.0362\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.6566 - loss: 0.9746 - val_accuracy: 0.6498 - val_loss: 0.9967\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.6883 - loss: 0.8934 - val_accuracy: 0.6554 - val_loss: 1.0023\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.7081 - loss: 0.8322 - val_accuracy: 0.6758 - val_loss: 0.9474\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.7233 - loss: 0.7906 - val_accuracy: 0.6819 - val_loss: 0.9350\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.7458 - loss: 0.7293 - val_accuracy: 0.6948 - val_loss: 0.9023\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.7620 - loss: 0.6845 - val_accuracy: 0.6853 - val_loss: 0.9272\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.7736 - loss: 0.6502 - val_accuracy: 0.6923 - val_loss: 0.9187\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7947 - loss: 0.5942\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7015 - loss: 0.9022\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.7852 - loss: 0.6153 - val_accuracy: 0.6905 - val_loss: 0.9521\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.7941 - loss: 0.5879 - val_accuracy: 0.6872 - val_loss: 0.9939\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8061 - loss: 0.5583 - val_accuracy: 0.6903 - val_loss: 0.9686\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8174 - loss: 0.5226 - val_accuracy: 0.6822 - val_loss: 1.0030\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8281 - loss: 0.4877 - val_accuracy: 0.6972 - val_loss: 1.0063\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8310 - loss: 0.4805 - val_accuracy: 0.6924 - val_loss: 1.0256\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8413 - loss: 0.4504 - val_accuracy: 0.6899 - val_loss: 1.0603\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.8486 - loss: 0.4311 - val_accuracy: 0.6857 - val_loss: 1.1084\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8536 - loss: 0.4134 - val_accuracy: 0.6909 - val_loss: 1.1669\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8622 - loss: 0.3849 - val_accuracy: 0.6770 - val_loss: 1.2210\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8696 - loss: 0.3669\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6842 - loss: 1.2001\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.8725 - loss: 0.3564 - val_accuracy: 0.6831 - val_loss: 1.2826\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8809 - loss: 0.3359 - val_accuracy: 0.6830 - val_loss: 1.2560\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8853 - loss: 0.3221 - val_accuracy: 0.6798 - val_loss: 1.3181\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8941 - loss: 0.3041 - val_accuracy: 0.6741 - val_loss: 1.3534\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8948 - loss: 0.2884 - val_accuracy: 0.6746 - val_loss: 1.4148\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.9028 - loss: 0.2756 - val_accuracy: 0.6653 - val_loss: 1.4919\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9094 - loss: 0.2589 - val_accuracy: 0.6752 - val_loss: 1.4651\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9120 - loss: 0.2462 - val_accuracy: 0.6737 - val_loss: 1.5446\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.9182 - loss: 0.2334 - val_accuracy: 0.6712 - val_loss: 1.5554\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9158 - loss: 0.2368 - val_accuracy: 0.6736 - val_loss: 1.6795\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9322 - loss: 0.1930\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6741 - loss: 1.6455\n",
      "(<class 'keras.src.layers.pooling.max_pooling2d.MaxPooling2D'>, 5)\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.3390 - loss: 1.7872 - val_accuracy: 0.5154 - val_loss: 1.3530\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.5425 - loss: 1.2719 - val_accuracy: 0.5682 - val_loss: 1.2082\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.6064 - loss: 1.1110 - val_accuracy: 0.6165 - val_loss: 1.0963\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6443 - loss: 1.0071 - val_accuracy: 0.6400 - val_loss: 1.0437\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.6706 - loss: 0.9361 - val_accuracy: 0.6622 - val_loss: 0.9876\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.6991 - loss: 0.8663 - val_accuracy: 0.6500 - val_loss: 1.0151\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.7161 - loss: 0.8115 - val_accuracy: 0.6706 - val_loss: 0.9615\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.7335 - loss: 0.7534 - val_accuracy: 0.6689 - val_loss: 0.9714\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.7474 - loss: 0.7216 - val_accuracy: 0.6775 - val_loss: 0.9552\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.7599 - loss: 0.6754 - val_accuracy: 0.6747 - val_loss: 0.9740\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7796 - loss: 0.6244\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6798 - loss: 0.9508\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.7739 - loss: 0.6416 - val_accuracy: 0.6825 - val_loss: 0.9614\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.7813 - loss: 0.6159 - val_accuracy: 0.6614 - val_loss: 1.0794\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.7930 - loss: 0.5897 - val_accuracy: 0.6684 - val_loss: 1.0585\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.8093 - loss: 0.5435 - val_accuracy: 0.6633 - val_loss: 1.0583\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.8050 - loss: 0.5440 - val_accuracy: 0.6726 - val_loss: 1.0666\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.8223 - loss: 0.5067 - val_accuracy: 0.6759 - val_loss: 1.0910\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.8359 - loss: 0.4661 - val_accuracy: 0.6699 - val_loss: 1.1463\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.8379 - loss: 0.4588 - val_accuracy: 0.6603 - val_loss: 1.1840\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.8437 - loss: 0.4438 - val_accuracy: 0.6656 - val_loss: 1.2159\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.8490 - loss: 0.4210 - val_accuracy: 0.6671 - val_loss: 1.2467\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8627 - loss: 0.3846\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6708 - loss: 1.2325\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.8607 - loss: 0.3972 - val_accuracy: 0.6658 - val_loss: 1.2819\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.8671 - loss: 0.3696 - val_accuracy: 0.6653 - val_loss: 1.3223\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.8711 - loss: 0.3610 - val_accuracy: 0.6634 - val_loss: 1.3566\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.8739 - loss: 0.3529 - val_accuracy: 0.6670 - val_loss: 1.3707\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.8838 - loss: 0.3272 - val_accuracy: 0.6598 - val_loss: 1.3929\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.8891 - loss: 0.3133 - val_accuracy: 0.6653 - val_loss: 1.4677\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.8914 - loss: 0.2986 - val_accuracy: 0.6610 - val_loss: 1.5475\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.8980 - loss: 0.2856 - val_accuracy: 0.6540 - val_loss: 1.5925\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9007 - loss: 0.2799 - val_accuracy: 0.6656 - val_loss: 1.5892\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.9044 - loss: 0.2664 - val_accuracy: 0.6599 - val_loss: 1.6998\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9182 - loss: 0.2293\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6633 - loss: 1.6573\n",
      "(<class 'keras.src.layers.pooling.average_pooling2d.AveragePooling2D'>, 2)\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.3609 - loss: 1.7478 - val_accuracy: 0.5089 - val_loss: 1.3689\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.5568 - loss: 1.2411 - val_accuracy: 0.5966 - val_loss: 1.1186\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.6132 - loss: 1.0907 - val_accuracy: 0.6257 - val_loss: 1.0650\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.6536 - loss: 0.9799 - val_accuracy: 0.6536 - val_loss: 0.9795\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.6845 - loss: 0.8985 - val_accuracy: 0.6633 - val_loss: 0.9520\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.7120 - loss: 0.8225 - val_accuracy: 0.6797 - val_loss: 0.9022\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.7318 - loss: 0.7652 - val_accuracy: 0.6941 - val_loss: 0.8785\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.7485 - loss: 0.7164 - val_accuracy: 0.6965 - val_loss: 0.8693\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.7645 - loss: 0.6737 - val_accuracy: 0.7120 - val_loss: 0.8478\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.7797 - loss: 0.6262 - val_accuracy: 0.7044 - val_loss: 0.8770\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7963 - loss: 0.5808\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7062 - loss: 0.8697\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.7923 - loss: 0.5957 - val_accuracy: 0.7189 - val_loss: 0.8446\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.8034 - loss: 0.5630 - val_accuracy: 0.7188 - val_loss: 0.8550\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.8149 - loss: 0.5267 - val_accuracy: 0.7002 - val_loss: 0.9122\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.8229 - loss: 0.5024 - val_accuracy: 0.7190 - val_loss: 0.8780\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.8340 - loss: 0.4679 - val_accuracy: 0.7128 - val_loss: 0.9213\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.8424 - loss: 0.4434 - val_accuracy: 0.7105 - val_loss: 0.9001\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.8486 - loss: 0.4252 - val_accuracy: 0.7148 - val_loss: 0.9502\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.8620 - loss: 0.3903 - val_accuracy: 0.7150 - val_loss: 0.9881\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.8656 - loss: 0.3786 - val_accuracy: 0.7102 - val_loss: 1.0108\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.8715 - loss: 0.3573 - val_accuracy: 0.7113 - val_loss: 1.0103\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8930 - loss: 0.3077\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7106 - loss: 1.0168\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.8809 - loss: 0.3346 - val_accuracy: 0.7036 - val_loss: 1.0778\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.8875 - loss: 0.3150 - val_accuracy: 0.6977 - val_loss: 1.1532\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.8938 - loss: 0.2991 - val_accuracy: 0.7056 - val_loss: 1.1624\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9005 - loss: 0.2802 - val_accuracy: 0.7008 - val_loss: 1.2054\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9107 - loss: 0.2564 - val_accuracy: 0.7033 - val_loss: 1.2155\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.9121 - loss: 0.2453 - val_accuracy: 0.6994 - val_loss: 1.3670\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9150 - loss: 0.2416 - val_accuracy: 0.6954 - val_loss: 1.3405\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9229 - loss: 0.2166 - val_accuracy: 0.7014 - val_loss: 1.4147\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.9263 - loss: 0.2065 - val_accuracy: 0.6960 - val_loss: 1.4293\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9299 - loss: 0.1936 - val_accuracy: 0.6920 - val_loss: 1.5392\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9239 - loss: 0.2116\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6917 - loss: 1.5436\n",
      "(<class 'keras.src.layers.pooling.average_pooling2d.AveragePooling2D'>, 3)\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.3357 - loss: 1.8038 - val_accuracy: 0.5202 - val_loss: 1.3312\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.5338 - loss: 1.2967 - val_accuracy: 0.5900 - val_loss: 1.1487\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.6013 - loss: 1.1222 - val_accuracy: 0.6127 - val_loss: 1.1176\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.6510 - loss: 0.9998 - val_accuracy: 0.6476 - val_loss: 1.0154\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.6749 - loss: 0.9182 - val_accuracy: 0.6537 - val_loss: 1.0110\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.7006 - loss: 0.8512 - val_accuracy: 0.6641 - val_loss: 0.9806\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.7232 - loss: 0.7970 - val_accuracy: 0.6925 - val_loss: 0.9047\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.7403 - loss: 0.7442 - val_accuracy: 0.6965 - val_loss: 0.8695\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.7563 - loss: 0.7025 - val_accuracy: 0.7006 - val_loss: 0.8757\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.7716 - loss: 0.6544 - val_accuracy: 0.7054 - val_loss: 0.8783\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7897 - loss: 0.6060\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7064 - loss: 0.8690\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.7825 - loss: 0.6254 - val_accuracy: 0.6984 - val_loss: 0.9086\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.7922 - loss: 0.5916 - val_accuracy: 0.6961 - val_loss: 0.9198\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.8050 - loss: 0.5526 - val_accuracy: 0.7004 - val_loss: 0.9288\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.8189 - loss: 0.5205 - val_accuracy: 0.7149 - val_loss: 0.8932\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.8296 - loss: 0.4887 - val_accuracy: 0.7057 - val_loss: 0.9492\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.8339 - loss: 0.4678 - val_accuracy: 0.7108 - val_loss: 0.9376\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.8480 - loss: 0.4309 - val_accuracy: 0.7194 - val_loss: 0.9514\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.8554 - loss: 0.4111 - val_accuracy: 0.7172 - val_loss: 0.9851\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.8632 - loss: 0.3875 - val_accuracy: 0.7094 - val_loss: 1.0434\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.8718 - loss: 0.3718 - val_accuracy: 0.7043 - val_loss: 1.0521\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8839 - loss: 0.3346\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7065 - loss: 1.0506\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.8757 - loss: 0.3484 - val_accuracy: 0.7106 - val_loss: 1.0821\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.8848 - loss: 0.3244 - val_accuracy: 0.7083 - val_loss: 1.1318\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.8941 - loss: 0.3005 - val_accuracy: 0.7053 - val_loss: 1.1374\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9003 - loss: 0.2875 - val_accuracy: 0.7068 - val_loss: 1.1561\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.9049 - loss: 0.2674 - val_accuracy: 0.7024 - val_loss: 1.2150\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9100 - loss: 0.2520 - val_accuracy: 0.6970 - val_loss: 1.3244\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9146 - loss: 0.2460 - val_accuracy: 0.6944 - val_loss: 1.3910\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9177 - loss: 0.2304 - val_accuracy: 0.7004 - val_loss: 1.4107\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9251 - loss: 0.2150 - val_accuracy: 0.6979 - val_loss: 1.4552\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.9297 - loss: 0.1966 - val_accuracy: 0.6912 - val_loss: 1.5035\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9265 - loss: 0.2035\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6957 - loss: 1.4771\n",
      "(<class 'keras.src.layers.pooling.average_pooling2d.AveragePooling2D'>, 4)\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.3206 - loss: 1.8309 - val_accuracy: 0.4925 - val_loss: 1.3830\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.5204 - loss: 1.3357 - val_accuracy: 0.5607 - val_loss: 1.2354\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.5826 - loss: 1.1777 - val_accuracy: 0.5890 - val_loss: 1.1606\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.6243 - loss: 1.0648 - val_accuracy: 0.6221 - val_loss: 1.0702\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.6545 - loss: 0.9794 - val_accuracy: 0.6416 - val_loss: 1.0297\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.6799 - loss: 0.9154 - val_accuracy: 0.6423 - val_loss: 1.0215\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.6977 - loss: 0.8634 - val_accuracy: 0.6680 - val_loss: 0.9608\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.7192 - loss: 0.8103 - val_accuracy: 0.6780 - val_loss: 0.9301\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.7351 - loss: 0.7607 - val_accuracy: 0.6794 - val_loss: 0.9550\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.7456 - loss: 0.7295 - val_accuracy: 0.6956 - val_loss: 0.9000\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7775 - loss: 0.6481\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7055 - loss: 0.8892\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.7551 - loss: 0.7041 - val_accuracy: 0.6896 - val_loss: 0.9213\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.7672 - loss: 0.6617 - val_accuracy: 0.6961 - val_loss: 0.9178\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.7810 - loss: 0.6293 - val_accuracy: 0.6875 - val_loss: 0.9389\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.7906 - loss: 0.5972 - val_accuracy: 0.6907 - val_loss: 0.9376\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.7999 - loss: 0.5692 - val_accuracy: 0.6959 - val_loss: 0.9495\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.8082 - loss: 0.5418 - val_accuracy: 0.6938 - val_loss: 0.9661\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.8158 - loss: 0.5295 - val_accuracy: 0.6965 - val_loss: 0.9769\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.8216 - loss: 0.5038 - val_accuracy: 0.6839 - val_loss: 1.0040\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.8301 - loss: 0.4830 - val_accuracy: 0.6870 - val_loss: 1.0574\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.8375 - loss: 0.4611 - val_accuracy: 0.6903 - val_loss: 1.0474\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8511 - loss: 0.4183\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6969 - loss: 1.0354\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.8457 - loss: 0.4359 - val_accuracy: 0.6934 - val_loss: 1.0577\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.8525 - loss: 0.4161 - val_accuracy: 0.6852 - val_loss: 1.1225\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.8590 - loss: 0.4016 - val_accuracy: 0.6890 - val_loss: 1.1097\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.8643 - loss: 0.3837 - val_accuracy: 0.6898 - val_loss: 1.1443\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.8730 - loss: 0.3629 - val_accuracy: 0.6838 - val_loss: 1.1749\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.8753 - loss: 0.3473 - val_accuracy: 0.6897 - val_loss: 1.1705\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.8799 - loss: 0.3352 - val_accuracy: 0.6859 - val_loss: 1.2343\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.8887 - loss: 0.3180 - val_accuracy: 0.6896 - val_loss: 1.2383\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.8944 - loss: 0.3009 - val_accuracy: 0.6842 - val_loss: 1.3233\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.8967 - loss: 0.2916 - val_accuracy: 0.6743 - val_loss: 1.3412\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8947 - loss: 0.2914\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6759 - loss: 1.3371\n",
      "(<class 'keras.src.layers.pooling.average_pooling2d.AveragePooling2D'>, 5)\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.3213 - loss: 1.8325 - val_accuracy: 0.4898 - val_loss: 1.4115\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.5174 - loss: 1.3485 - val_accuracy: 0.5387 - val_loss: 1.2713\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5680 - loss: 1.1974 - val_accuracy: 0.5940 - val_loss: 1.1336\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6194 - loss: 1.0761 - val_accuracy: 0.6139 - val_loss: 1.0812\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.6533 - loss: 0.9883 - val_accuracy: 0.6222 - val_loss: 1.0639\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6799 - loss: 0.9145 - val_accuracy: 0.6567 - val_loss: 0.9780\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6952 - loss: 0.8676 - val_accuracy: 0.6647 - val_loss: 0.9474\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.7166 - loss: 0.8148 - val_accuracy: 0.6529 - val_loss: 0.9980\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.7289 - loss: 0.7764 - val_accuracy: 0.6568 - val_loss: 0.9931\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.7404 - loss: 0.7356 - val_accuracy: 0.6706 - val_loss: 0.9708\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7564 - loss: 0.6992\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6711 - loss: 0.9664\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.7477 - loss: 0.7113 - val_accuracy: 0.6829 - val_loss: 0.9512\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.7656 - loss: 0.6740 - val_accuracy: 0.6623 - val_loss: 1.0226\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.7738 - loss: 0.6412 - val_accuracy: 0.6739 - val_loss: 0.9854\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.7824 - loss: 0.6116 - val_accuracy: 0.6794 - val_loss: 0.9637\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.7933 - loss: 0.5894 - val_accuracy: 0.6834 - val_loss: 0.9961\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.8025 - loss: 0.5710 - val_accuracy: 0.6920 - val_loss: 0.9676\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - accuracy: 0.8160 - loss: 0.5300 - val_accuracy: 0.6847 - val_loss: 1.0114\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.8164 - loss: 0.5217 - val_accuracy: 0.6803 - val_loss: 1.0565\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.8266 - loss: 0.4919 - val_accuracy: 0.6855 - val_loss: 1.0453\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.8325 - loss: 0.4764 - val_accuracy: 0.6863 - val_loss: 1.0935\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8515 - loss: 0.4282\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6900 - loss: 1.0827\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.8423 - loss: 0.4528 - val_accuracy: 0.6827 - val_loss: 1.1862\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.8471 - loss: 0.4373 - val_accuracy: 0.6841 - val_loss: 1.1168\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.8536 - loss: 0.4245 - val_accuracy: 0.6839 - val_loss: 1.1327\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.8574 - loss: 0.4044 - val_accuracy: 0.6799 - val_loss: 1.1874\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.8623 - loss: 0.3962 - val_accuracy: 0.6774 - val_loss: 1.2459\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.8686 - loss: 0.3725 - val_accuracy: 0.6660 - val_loss: 1.2777\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.8726 - loss: 0.3666 - val_accuracy: 0.6703 - val_loss: 1.3203\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.8773 - loss: 0.3449 - val_accuracy: 0.6662 - val_loss: 1.3486\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.8797 - loss: 0.3373 - val_accuracy: 0.6723 - val_loss: 1.3892\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.8906 - loss: 0.3119 - val_accuracy: 0.6701 - val_loss: 1.4134\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8940 - loss: 0.2994\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6747 - loss: 1.3817\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame(columns = ['pooling_type', 'conv_width', 'epochs', 'train_loss', 'train_acc', 'test_loss', 'test_acc'])\n",
    "results_df.set_index(['pooling_type', 'conv_width', 'epochs'], inplace=True)\n",
    "\n",
    "for key, model in model_dict.items():\n",
    "    print(key)\n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "                  loss=losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy'])\n",
    "    total_epochs = 0\n",
    "    for i in range(3):\n",
    "        history = model.fit(x_train, y_train, epochs=10, batch_size = 32, validation_data = (x_test, y_test))\n",
    "        total_epochs += 10\n",
    "        results_df.loc[(map_function_to_str(key[0]), key[1], total_epochs)] = [*model.evaluate(x_train, y_train), *model.evaluate(x_test, y_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695fa99c-da2e-493a-9b92-0dc8841bf0dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0579bb5-72d9-4947-baf5-784e55e9149f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_pickle(\"overview_results.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e461ddb1-bc49-46dc-a6f6-5d87152d8bdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_acc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pooling_type</th>\n",
       "      <th>conv_width</th>\n",
       "      <th>epochs</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"12\" valign=\"top\">max_pooling</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">2</th>\n",
       "      <th>10</th>\n",
       "      <td>0.530640</td>\n",
       "      <td>0.81684</td>\n",
       "      <td>0.846120</td>\n",
       "      <td>0.7151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.278665</td>\n",
       "      <td>0.90172</td>\n",
       "      <td>1.147582</td>\n",
       "      <td>0.7076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.154934</td>\n",
       "      <td>0.94554</td>\n",
       "      <td>1.589165</td>\n",
       "      <td>0.7002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">3</th>\n",
       "      <th>10</th>\n",
       "      <td>0.560669</td>\n",
       "      <td>0.80432</td>\n",
       "      <td>0.853877</td>\n",
       "      <td>0.7094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.361318</td>\n",
       "      <td>0.86962</td>\n",
       "      <td>1.109978</td>\n",
       "      <td>0.7038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.208267</td>\n",
       "      <td>0.92452</td>\n",
       "      <td>1.493825</td>\n",
       "      <td>0.6911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">4</th>\n",
       "      <th>10</th>\n",
       "      <td>0.593885</td>\n",
       "      <td>0.79548</td>\n",
       "      <td>0.918653</td>\n",
       "      <td>0.6923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.362562</td>\n",
       "      <td>0.87080</td>\n",
       "      <td>1.221033</td>\n",
       "      <td>0.6770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.192852</td>\n",
       "      <td>0.93114</td>\n",
       "      <td>1.679461</td>\n",
       "      <td>0.6736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">5</th>\n",
       "      <th>10</th>\n",
       "      <td>0.628810</td>\n",
       "      <td>0.78002</td>\n",
       "      <td>0.974006</td>\n",
       "      <td>0.6747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.388318</td>\n",
       "      <td>0.86186</td>\n",
       "      <td>1.246670</td>\n",
       "      <td>0.6671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.229943</td>\n",
       "      <td>0.91802</td>\n",
       "      <td>1.699771</td>\n",
       "      <td>0.6599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"12\" valign=\"top\">average_pooling</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">2</th>\n",
       "      <th>10</th>\n",
       "      <td>0.582531</td>\n",
       "      <td>0.79642</td>\n",
       "      <td>0.876977</td>\n",
       "      <td>0.7044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.306805</td>\n",
       "      <td>0.89332</td>\n",
       "      <td>1.010255</td>\n",
       "      <td>0.7113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.213017</td>\n",
       "      <td>0.92306</td>\n",
       "      <td>1.539235</td>\n",
       "      <td>0.6920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">3</th>\n",
       "      <th>10</th>\n",
       "      <td>0.608510</td>\n",
       "      <td>0.78806</td>\n",
       "      <td>0.878340</td>\n",
       "      <td>0.7054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.337726</td>\n",
       "      <td>0.88280</td>\n",
       "      <td>1.052060</td>\n",
       "      <td>0.7043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.204728</td>\n",
       "      <td>0.92638</td>\n",
       "      <td>1.503497</td>\n",
       "      <td>0.6912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">4</th>\n",
       "      <th>10</th>\n",
       "      <td>0.646895</td>\n",
       "      <td>0.77652</td>\n",
       "      <td>0.900004</td>\n",
       "      <td>0.6956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.421646</td>\n",
       "      <td>0.85012</td>\n",
       "      <td>1.047421</td>\n",
       "      <td>0.6903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.294018</td>\n",
       "      <td>0.89456</td>\n",
       "      <td>1.341204</td>\n",
       "      <td>0.6743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">5</th>\n",
       "      <th>10</th>\n",
       "      <td>0.703407</td>\n",
       "      <td>0.75562</td>\n",
       "      <td>0.970828</td>\n",
       "      <td>0.6706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.427579</td>\n",
       "      <td>0.85160</td>\n",
       "      <td>1.093545</td>\n",
       "      <td>0.6863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.302296</td>\n",
       "      <td>0.89340</td>\n",
       "      <td>1.413385</td>\n",
       "      <td>0.6701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   train_loss  train_acc  test_loss  test_acc\n",
       "pooling_type    conv_width epochs                                            \n",
       "max_pooling     2          10        0.530640    0.81684   0.846120    0.7151\n",
       "                           20        0.278665    0.90172   1.147582    0.7076\n",
       "                           30        0.154934    0.94554   1.589165    0.7002\n",
       "                3          10        0.560669    0.80432   0.853877    0.7094\n",
       "                           20        0.361318    0.86962   1.109978    0.7038\n",
       "                           30        0.208267    0.92452   1.493825    0.6911\n",
       "                4          10        0.593885    0.79548   0.918653    0.6923\n",
       "                           20        0.362562    0.87080   1.221033    0.6770\n",
       "                           30        0.192852    0.93114   1.679461    0.6736\n",
       "                5          10        0.628810    0.78002   0.974006    0.6747\n",
       "                           20        0.388318    0.86186   1.246670    0.6671\n",
       "                           30        0.229943    0.91802   1.699771    0.6599\n",
       "average_pooling 2          10        0.582531    0.79642   0.876977    0.7044\n",
       "                           20        0.306805    0.89332   1.010255    0.7113\n",
       "                           30        0.213017    0.92306   1.539235    0.6920\n",
       "                3          10        0.608510    0.78806   0.878340    0.7054\n",
       "                           20        0.337726    0.88280   1.052060    0.7043\n",
       "                           30        0.204728    0.92638   1.503497    0.6912\n",
       "                4          10        0.646895    0.77652   0.900004    0.6956\n",
       "                           20        0.421646    0.85012   1.047421    0.6903\n",
       "                           30        0.294018    0.89456   1.341204    0.6743\n",
       "                5          10        0.703407    0.75562   0.970828    0.6706\n",
       "                           20        0.427579    0.85160   1.093545    0.6863\n",
       "                           30        0.302296    0.89340   1.413385    0.6701"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.groupby(level='conv_width').mean()\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b331d474-f5a2-46a4-ad49-2a10f6be573d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example to make sure I understand how these images work\n",
    "data = unpickle('cifar-10-python.tar.gz', 'test', 1)\n",
    "image_flat = data[b'data'][0]\n",
    "image = convert_flat_to_matrix(image_flat)\n",
    "\n",
    "# Display the image\n",
    "plt.imshow(image)\n",
    "plt.title(f'Image {0}')\n",
    "plt.show()\n",
    "\n",
    "data[b'labels'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb33d2e1-7296-4511-9888-67c5f97046b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Shape of predictions: (10000, 10)\n",
      "First prediction: [ -5.520808   -6.5533013   1.0991428   9.181097   -7.560939    7.6534185\n",
      "  -1.0345199 -11.420007    0.5848202  -8.03133  ]\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Shape of predictions: (10000, 10)\n",
      "First prediction: [ -2.8931742   -6.6320977   -3.344149     5.1254907   -3.545172\n",
      "  -1.0676231    2.8325503  -10.172999    -1.5197906    0.20364209]\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Shape of predictions: (10000, 10)\n",
      "First prediction: [ -3.0737298    2.2114558   -3.8698924    4.548421    -5.407115\n",
      "  -2.4067094    5.1069093  -11.174124     2.6445363   -0.38196987]\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Shape of predictions: (10000, 10)\n",
      "First prediction: [-7.773814  -9.346449  -2.1947742  7.1061296 -5.3289423  1.0466788\n",
      "  1.1308538 -2.070793  -1.7019196 -6.6117463]\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Shape of predictions: (10000, 10)\n",
      "First prediction: [ -8.909422   -7.706595   -6.2457256   8.816957  -13.951702    3.280926\n",
      "  -3.9979885 -12.200002    1.0931127  -3.524115 ]\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Shape of predictions: (10000, 10)\n",
      "First prediction: [ -2.5245717  -2.4715397  -9.582075   11.401618  -12.136088   -2.2635093\n",
      "  -3.0028663  -4.9778643   3.6007998  -9.3930435]\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Shape of predictions: (10000, 10)\n",
      "First prediction: [-2.4418936  -5.8941545  -2.5404634   6.116573   -4.6793966   3.680862\n",
      " -0.05473845 -7.075842    1.2164661  -7.011131  ]\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Shape of predictions: (10000, 10)\n",
      "First prediction: [-5.158971   -4.5661573  -3.68323     5.572831   -8.270491   -0.98836625\n",
      "  0.7302127  -8.674493   -1.4264423  -7.126892  ]\n"
     ]
    }
   ],
   "source": [
    "for key, model in model_dict.items():\n",
    "    predictions = model.predict(x_test)\n",
    "\n",
    "    # Example output shapes\n",
    "    print('Shape of predictions:', predictions.shape)  # Shape will depend on your model and task\n",
    "    \n",
    "    # Example of accessing predictions for the first sample\n",
    "    first_prediction = predictions[0]\n",
    "    print('First prediction:', first_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1d8066e-9f76-4fac-b51f-e51dbdf67ea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.1614995e-05, 3.9103066e-05, 9.4549898e-05, 9.8973185e-01,\n",
       "       9.6258543e-07, 1.3996704e-03, 7.8053987e-03, 6.4266317e-07,\n",
       "       9.0317475e-04, 3.0206322e-06], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(first_prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
